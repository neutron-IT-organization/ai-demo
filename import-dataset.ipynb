{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990fad49-09ea-43a5-af3b-cb9bebd331d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import shutil\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29213e78-3818-4473-958c-76d2e51bc313",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"basketball-dataset\"\n",
    "LOCAL_DATASET_PATH = \"basketball-dataset/\"\n",
    "\n",
    "TRAIN_RATIO = 0.80\n",
    "VAL_RATIO = 0.15\n",
    "TEST_RATIO = 0.05\n",
    "\n",
    "AWS_ACCESS_KEY_ID = os.environ.get(\"AWS_ACCESS_KEY_ID\")\n",
    "AWS_SECRET_ACCESS_KEY = os.environ.get(\"AWS_SECRET_ACCESS_KEY\")\n",
    "AWS_S3_BUCKET = os.environ.get(\"AWS_S3_BUCKET\")\n",
    "AWS_S3_ENDPOINT = os.environ.get(\"AWS_S3_ENDPOINT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d80ecf8-9f44-454a-8e0c-4dbfa479fef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = boto3.Session(\n",
    "    aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
    "    aws_secret_access_key=AWS_SECRET_ACCESS_KEY\n",
    ")\n",
    "client = session.client(\"s3\", endpoint_url=AWS_S3_ENDPOINT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ea27b2-cedc-4412-b0a7-4caa3cf3167e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_files(bucket_name, folder):\n",
    "    paginator = client.get_paginator('list_objects_v2')\n",
    "    operation_parameters = {'Bucket': bucket_name, 'Prefix': folder}\n",
    "    page_iterator = paginator.paginate(**operation_parameters)\n",
    "    total_files = 0\n",
    "    for page in page_iterator:\n",
    "        if 'Contents' in page:\n",
    "            total_files += len(page['Contents'])\n",
    "    return total_files\n",
    "\n",
    "def download_file(bucket_name, key, local_file_path):\n",
    "    try:\n",
    "        os.makedirs(os.path.dirname(local_file_path), exist_ok=True)\n",
    "        client.download_file(bucket_name, key, local_file_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading {key}: {e}\")\n",
    "\n",
    "def download_folder(bucket_name, folder, local_dir=None):\n",
    "    if local_dir is None:\n",
    "        local_dir = os.getcwd()\n",
    "\n",
    "    os.makedirs(local_dir, exist_ok=True)\n",
    "\n",
    "    # Count the total number of files\n",
    "    total_files = count_files(bucket_name, folder)\n",
    "\n",
    "    paginator = client.get_paginator('list_objects_v2')\n",
    "    operation_parameters = {'Bucket': bucket_name, 'Prefix': folder}\n",
    "    page_iterator = paginator.paginate(**operation_parameters)\n",
    "\n",
    "    # Use ThreadPoolExecutor to download files concurrently\n",
    "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        with tqdm(total=total_files, desc=\"Downloading files\", unit=\"file\") as pbar:\n",
    "            for page in page_iterator:\n",
    "                if 'Contents' in page:\n",
    "                    for obj in page['Contents']:\n",
    "                        key = obj['Key']\n",
    "                        relative_path = os.path.relpath(key, folder)\n",
    "                        local_file_path = os.path.join(local_dir, relative_path)\n",
    "\n",
    "                        # Submit download task to the executor\n",
    "                        executor.submit(download_file, bucket_name, key, local_file_path)\n",
    "                        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394f5d7f-4d7a-4cbd-83c7-e47032d4b0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(image_dir, label_dir, output_dir, train_ratio, val_ratio, test_ratio):\n",
    "    # Create output directories\n",
    "    train_image_dir = os.path.join(output_dir, 'images', 'train')\n",
    "    train_label_dir = os.path.join(output_dir, 'labels', 'train')\n",
    "    val_image_dir = os.path.join(output_dir, 'images', 'val')\n",
    "    val_label_dir = os.path.join(output_dir, 'labels', 'val')\n",
    "    test_image_dir = os.path.join(output_dir, 'images', 'test')\n",
    "    test_label_dir = os.path.join(output_dir, 'labels', 'test')\n",
    "\n",
    "    os.makedirs(train_image_dir, exist_ok=True)\n",
    "    os.makedirs(train_label_dir, exist_ok=True)\n",
    "    os.makedirs(val_image_dir, exist_ok=True)\n",
    "    os.makedirs(val_label_dir, exist_ok=True)\n",
    "    os.makedirs(test_image_dir, exist_ok=True)\n",
    "    os.makedirs(test_label_dir, exist_ok=True)\n",
    "\n",
    "    # Get list of image files\n",
    "    image_files = [f for f in os.listdir(image_dir) if os.path.isfile(os.path.join(image_dir, f))]\n",
    "    random.shuffle(image_files)\n",
    "\n",
    "    # Split dataset\n",
    "    train_files, test_files = train_test_split(image_files, test_size=test_ratio, random_state=42)\n",
    "    train_files, val_files = train_test_split(train_files, test_size=val_ratio/(train_ratio+val_ratio), random_state=42)\n",
    "\n",
    "    # Function to move files\n",
    "    def move_files(files, image_dest, label_dest):\n",
    "        for file in files:\n",
    "            base_name = os.path.splitext(file)[0]\n",
    "            image_src = os.path.join(image_dir, file)\n",
    "            label_src = os.path.join(label_dir, base_name + '.txt')\n",
    "\n",
    "            shutil.move(image_src, os.path.join(image_dest, file))\n",
    "            shutil.move(label_src, os.path.join(label_dest, base_name + '.txt'))\n",
    "\n",
    "    # Move files to respective directories\n",
    "    move_files(train_files, train_image_dir, train_label_dir)\n",
    "    move_files(val_files, val_image_dir, val_label_dir)\n",
    "    move_files(test_files, test_image_dir, test_label_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c9f081-2bff-4e6d-86e3-3c3074152c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(LOCAL_DATASET_PATH):\n",
    "    shutil.rmtree(LOCAL_DATASET_PATH)\n",
    "download_folder(AWS_S3_BUCKET, DATASET_PATH, LOCAL_DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a77c72-a7ed-49a1-94d5-75c0c68f0b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_dataset(LOCAL_DATASET_PATH + 'images', LOCAL_DATASET_PATH + 'labels', LOCAL_DATASET_PATH, TRAIN_RATIO, VAL_RATIO, TEST_RATIO)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
